{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Youtube Data Machine Learning Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the libraries needed\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the dataset\n",
    "df = pd.read_csv('youtube_channel_real_performance_analytics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Cleaning and preprocessing field\n",
    "df_copy = df #all the changes will be applied to the df_copy data frame\n",
    "df_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Cleaning and preprocessing \n",
    "#Handling Missing Values\n",
    "df_copy.isnull().sum() #Checking for the total null values for each column in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#droping the unnecessary column\n",
    "df_copy.drop(columns=['ID'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy['Video Publish Time'] = pd.to_datetime(df['Video Publish Time'],errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy['Publish Hour'] = df['Video Publish Time'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy['Publish Hour']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy['Publish Hour'] = df['Video Publish Time'].dt.hour\n",
    "df_copy['Publish Day'] = df['Video Publish Time'].dt.day\n",
    "df_copy['Publish Month'] = df['Video Publish Time'].dt.month\n",
    "df_copy['Publish Year'] = df['Video Publish Time'].dt.year\n",
    "df_copy['Publish Weekday'] = df['Video Publish Time'].dt.weekday\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy[['Publish Hour','Publish Day','Publish Month','Publish Year','Publish Weekday']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping the irrelavant column \"Video Publish Time\"\n",
    "df_copy.drop(columns=['Video Publish Time'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#select columns with numerical values\n",
    "num_cols = df_copy.select_dtypes(include=['number']).columns\n",
    "num_cols\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "for i,col in enumerate(num_cols[:9]):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    sns.histplot(df[col],kde = True)\n",
    "    plt.title(col)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "for i,col in enumerate(num_cols[9:18]):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    sns.histplot(df[col],kde = True)\n",
    "    plt.title(col)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "for i,col in enumerate(num_cols[18:27]):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    sns.histplot(df[col],kde = True)\n",
    "    plt.title(col)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "for i,col in enumerate(num_cols[27:36]):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    sns.histplot(df[col],kde = True)\n",
    "    plt.title(col)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "for i,col in enumerate(num_cols[36:45]):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    sns.histplot(df[col],kde = True)\n",
    "    plt.title(col)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "for i,col in enumerate(num_cols[45:54]):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    sns.histplot(df[col],kde = True)\n",
    "    plt.title(col)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "for i,col in enumerate(num_cols[54:63]):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    sns.histplot(df[col],kde = True)\n",
    "    plt.title(col)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "for i,col in enumerate(num_cols[63:70]):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    sns.histplot(df[col],kde = True)\n",
    "    plt.title(col)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From the above plots \n",
    "#Columns to standardize are \n",
    "#All columns having normal distribution like plot are to be normalized\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New Comments,Share,Likes,Dislikes,Like Rate(%),Unsubscribes,New Subscribers,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now since the values in different columns are in different range therefore there is a \n",
    "#need to standardize and normalize the columns\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "\n",
    "min_max_scalar = MinMaxScaler()\n",
    "standard_scalar = StandardScaler()\n",
    "\n",
    "normalize_cols = [\n",
    "    \"Views\", \"Likes\", \"Dislikes\", \"New Comments\", \"Shares\", \"Subscribers\",\n",
    "    \"Estimated Revenue (USD)\", \"Monetized Playbacks (Estimate)\",\n",
    "    \"Watch Time (hours)\", \"Impressions\", \"Video Thumbnail CTR (%)\"\n",
    "]\n",
    "\n",
    "# Columns to standardize (mean = 0, std = 1)\n",
    "standardize_cols = [\n",
    "    \"Average View Percentage (%)\", \"Average View Duration\",\n",
    "    \"Revenue per 1000 Views (USD)\", \"Publish Hour\", \"Publish Weekday\"\n",
    "]\n",
    "\n",
    "\n",
    "df_copy[normalize_cols] = min_max_scalar.fit_transform(df_copy[normalize_cols])\n",
    "df_copy[standardize_cols] = standard_scalar.fit_transform(df_copy[standardize_cols])\n",
    "\n",
    "df_copy.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the target variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"Estimated Revenue (USD)\"\n",
    "X = df_copy.drop(columns=target).select_dtypes(include=['number'])\n",
    "y = df_copy[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Test Split \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Training \n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "model = regressor.fit(X_train,y_train)\n",
    "y_pred = regressor.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error,r2_score,mean_absolute_error\n",
    "mse = mean_squared_error(y_test,y_pred)\n",
    "mae = mean_absolute_error(y_test,y_pred)\n",
    "r2score = r2_score(y_test,y_pred)\n",
    "print(\"MSE : \",mse)\n",
    "print(\"MAE : \",mae)\n",
    "print(\"R2score : \",r2score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying Random forest regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "forest_regressor = RandomForestRegressor()\n",
    "forest_regressor.fit(X_train,y_train)\n",
    "y_pred = forest_regressor.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test,y_pred)\n",
    "mae = mean_absolute_error(y_test,y_pred)\n",
    "r2score = r2_score(y_test,y_pred)\n",
    "print(\"MSE : \",mse) #lower is better\n",
    "print(\"MAE : \",mae) #lower is better\n",
    "print(\"R2score : \",r2score) #Closer to 1 is better\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract important feature\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "feature_importances = forest_regressor.feature_importances_\n",
    "feature_importances\n",
    "\n",
    "feature_df = pd.DataFrame({\"Feature\":X.columns,\"Importances\":feature_importances})\n",
    "feature_df = feature_df.sort_values(by=\"Importances\",ascending=False)\n",
    "feature_df\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12,15))\n",
    "plt.barh(feature_df['Feature'],feature_df['Importances'],color= 'skyblue')\n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.ylabel(\"Feature Name\")\n",
    "plt.title(\"Feature Importance for Predicting Views\")\n",
    "plt.gca().invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df.head(10)[\"Feature\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    \"XGBoost\": XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42),\n",
    "    \"Linear Regression\": LinearRegression()\n",
    "}\n",
    "\n",
    "# Dictionary to store results\n",
    "results = {}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)  # Train model\n",
    "    y_pred = model.predict(X_test)  # Make predictions\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    # Store results\n",
    "    results[name] = {\"MAE\": mae, \"MSE\": mse, \"RÂ² Score\": r2}\n",
    "\n",
    "# Convert results to DataFrame for easy comparison\n",
    "import pandas as pd\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Calculate VIF for each feature\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Feature\"] = X.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "\n",
    "# Display results\n",
    "print(vif_data.sort_values(by=\"VIF\", ascending=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define hyperparameter grid\n",
    "param_grid = {\"alpha\": [0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "# Ridge Regression (L2 Regularization)\n",
    "ridge = GridSearchCV(Ridge(), param_grid, cv=5, scoring='r2')\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "# Lasso Regression (L1 Regularization)\n",
    "lasso = GridSearchCV(Lasso(), param_grid, cv=5, scoring='r2')\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "# Print best alpha values\n",
    "print(f\"Best Ridge alpha: {ridge.best_params_['alpha']}\")\n",
    "print(f\"Best Lasso alpha: {lasso.best_params_['alpha']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Use the best models\n",
    "best_ridge = Ridge(alpha=ridge.best_params_[\"alpha\"])\n",
    "best_lasso = Lasso(alpha=lasso.best_params_[\"alpha\"])\n",
    "\n",
    "# Train models\n",
    "best_ridge.fit(X_train, y_train)\n",
    "best_lasso.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_ridge = best_ridge.predict(X_test)\n",
    "y_pred_lasso = best_lasso.predict(X_test)\n",
    "\n",
    "# Compare performance\n",
    "print(\" Ridge Regression Performance:\")\n",
    "print(\"MAE:\", mean_absolute_error(y_test, y_pred_ridge))\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred_ridge))\n",
    "print(\"RÂ² Score:\", r2_score(y_test, y_pred_ridge))\n",
    "\n",
    "print(\"\\n Lasso Regression Performance:\")\n",
    "print(\"MAE:\", mean_absolute_error(y_test, y_pred_lasso))\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred_lasso))\n",
    "print(\"RÂ² Score:\", r2_score(y_test, y_pred_lasso))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Train Lasso model with the best alpha value from tuning\n",
    "lasso = Lasso(alpha=lasso.best_params_[\"alpha\"])\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importance\n",
    "feature_importance = pd.DataFrame({\"Feature\": X.columns, \"Coefficient\": lasso.coef_})\n",
    "\n",
    "# Select features with non-zero coefficients\n",
    "selected_features = feature_importance[feature_importance[\"Coefficient\"] != 0]\n",
    "print(\"ðŸ“Œ Selected Features based on Lasso:\")\n",
    "print(selected_features.sort_values(by=\"Coefficient\", ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Initialize model\n",
    "lr = LinearRegression()\n",
    "\n",
    "# Apply RFE to select top 10 features\n",
    "rfe = RFE(lr, n_features_to_select=10)\n",
    "rfe.fit(X_train, y_train)\n",
    "\n",
    "# Get selected features\n",
    "selected_features_rfe = X.columns[rfe.support_]\n",
    "print(\"Selected Features using RFE:\", list(selected_features_rfe))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Train Random Forest model\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importance scores\n",
    "feature_importance_rf = pd.DataFrame({\"Feature\": X.columns, \"Importance\": rf.feature_importances_})\n",
    "feature_importance_rf = feature_importance_rf.sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(10, 15))\n",
    "plt.barh(feature_importance_rf[\"Feature\"], feature_importance_rf[\"Importance\"], color=\"gold\")\n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.ylabel(\"Feature Name\")\n",
    "plt.title(\"Feature Importance for Revenue Prediction (Random Forest)\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use features selected by Lasso (or replace with RFE/Random Forest)\n",
    "selected_features = [\"Watch Time (hours)\", \"Monetized Playbacks (Estimate)\", \n",
    "                     \"Revenue per 1000 Views (USD)\", \"Impressions\", \n",
    "                     \"Video Thumbnail CTR (%)\", \"Average View Duration\"]\n",
    "\n",
    "# Update X with only selected features\n",
    "X_selected = X[selected_features]\n",
    "\n",
    "# Split into train & test sets again\n",
    "X_train_sel, X_test_sel, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Initialize model\n",
    "lr_optimized = LinearRegression()\n",
    "\n",
    "# Train model\n",
    "lr_optimized.fit(X_train_sel, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_optimized = lr_optimized.predict(X_test_sel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Evaluate old model (before feature selection)\n",
    "y_pred_old = regressor.predict(X_test)  # Model before feature selection\n",
    "\n",
    "# Evaluate new optimized model\n",
    "mae_old = mean_absolute_error(y_test, y_pred_old)\n",
    "mse_old = mean_squared_error(y_test, y_pred_old)\n",
    "r2_old = r2_score(y_test, y_pred_old)\n",
    "\n",
    "mae_new = mean_absolute_error(y_test, y_pred_optimized)\n",
    "mse_new = mean_squared_error(y_test, y_pred_optimized)\n",
    "r2_new = r2_score(y_test, y_pred_optimized)\n",
    "\n",
    "# Print comparison\n",
    "print(\"Performance Comparison:\")\n",
    "print(f\" Before Feature Selection: MAE = {mae_old:.4f}, MSE = {mse_old:.4f}, RÂ² = {r2_old:.4f}\")\n",
    "print(f\" After Feature Selection: MAE = {mae_new:.4f}, MSE = {mse_new:.4f}, RÂ² = {r2_new:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define hyperparameter grid for Ridge & Lasso\n",
    "param_grid = {\"alpha\": [0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "# Ridge Regression (L2 Regularization)\n",
    "ridge_tuned = GridSearchCV(Ridge(), param_grid, cv=5, scoring='r2')\n",
    "ridge_tuned.fit(X_train_sel, y_train)\n",
    "\n",
    "# Lasso Regression (L1 Regularization)\n",
    "lasso_tuned = GridSearchCV(Lasso(), param_grid, cv=5, scoring='r2')\n",
    "lasso_tuned.fit(X_train_sel, y_train)\n",
    "\n",
    "# Print best hyperparameters\n",
    "print(f\"Best Ridge alpha: {ridge_tuned.best_params_['alpha']}\")\n",
    "print(f\"Best Lasso alpha: {lasso_tuned.best_params_['alpha']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Ridge & Lasso with best alpha\n",
    "best_ridge = Ridge(alpha=ridge_tuned.best_params_[\"alpha\"])\n",
    "best_lasso = Lasso(alpha=lasso_tuned.best_params_[\"alpha\"])\n",
    "\n",
    "best_ridge.fit(X_train_sel, y_train)\n",
    "best_lasso.fit(X_train_sel, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_ridge = best_ridge.predict(X_test_sel)\n",
    "y_pred_lasso = best_lasso.predict(X_test_sel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Evaluate models\n",
    "mae_ridge = mean_absolute_error(y_test, y_pred_ridge)\n",
    "mse_ridge = mean_squared_error(y_test, y_pred_ridge)\n",
    "r2_ridge = r2_score(y_test, y_pred_ridge)\n",
    "\n",
    "mae_lasso = mean_absolute_error(y_test, y_pred_lasso)\n",
    "mse_lasso = mean_squared_error(y_test, y_pred_lasso)\n",
    "r2_lasso = r2_score(y_test, y_pred_lasso)\n",
    "\n",
    "# Print results\n",
    "print(\"Performance After Hyperparameter Tuning:\")\n",
    "print(f\"Ridge: MAE = {mae_ridge:.4f}, MSE = {mse_ridge:.4f}, RÂ² = {r2_ridge:.4f}\")\n",
    "print(f\"Lasso: MAE = {mae_lasso:.4f}, MSE = {mse_lasso:.4f}, RÂ² = {r2_lasso:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get feature importance from Ridge\n",
    "feature_importance = pd.DataFrame({\n",
    "    \"Feature\": X_selected.columns,\n",
    "    \"Coefficient\": best_ridge.coef_\n",
    "})\n",
    "\n",
    "# Sort by absolute importance\n",
    "feature_importance = feature_importance.reindex(feature_importance[\"Coefficient\"].abs().sort_values(ascending=False).index)\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.barh(feature_importance[\"Feature\"], feature_importance[\"Coefficient\"], color=\"royalblue\")\n",
    "plt.xlabel(\"Coefficient Value\")\n",
    "plt.ylabel(\"Feature Name\")\n",
    "plt.title(\"ðŸ“Š Feature Impact on Revenue (Ridge Regression)\")\n",
    "plt.axvline(0, color='black', linestyle='--')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()\n",
    "\n",
    "# Print top contributing features\n",
    "print(\"Features that Increase Revenue:\")\n",
    "print(feature_importance[feature_importance[\"Coefficient\"] > 0])\n",
    "\n",
    "print(\"\\nFeatures that Decrease Revenue:\")\n",
    "print(feature_importance[feature_importance[\"Coefficient\"] < 0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(best_ridge,\"revenue_prediction_model.pkl\")\n",
    "\n",
    "joblib.dump(selected_features,\"Selected_features.pkl\")\n",
    "\n",
    "print(\"Model saved successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "loaded_model = joblib.load(\"revenue_prediction_model.pkl\")\n",
    "selected_features = joblib.load(\"selected_features.pkl\")\n",
    "\n",
    "# Example new video data (replace with real input)\n",
    "new_video_data = pd.DataFrame({\n",
    "    \"Watch Time (hours)\": [100],\n",
    "    \"Monetized Playbacks (Estimate)\": [5000],\n",
    "    \"Revenue per 1000 Views (USD)\": [2.5],\n",
    "    \"Impressions\": [20000],\n",
    "    \"Video Thumbnail CTR (%)\": [4.5],\n",
    "    \"Average View Duration\": [300]  # seconds\n",
    "})\n",
    "\n",
    "# Predict estimated revenue\n",
    "predicted_revenue = loaded_model.predict(new_video_data)\n",
    "print(f\"Predicted Revenue: ${predicted_revenue[0]:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from fastapi import FastAPI\n",
    "import uvicorn\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# Load the trained model & features\n",
    "model = joblib.load(\"revenue_prediction_model.pkl\")\n",
    "selected_features = joblib.load(\"selected_features.pkl\")\n",
    "\n",
    "# Initialize FastAPI\n",
    "app = FastAPI()\n",
    "\n",
    "@app.post(\"/predict/\")\n",
    "def predict_revenue(new_video_data):\n",
    "    # Convert input data to DataFrame\n",
    "    input_data = new_video_data\n",
    "\n",
    "    # Ensure only selected features are used\n",
    "    input_data = input_data[selected_features]\n",
    "\n",
    "    # Predict revenue\n",
    "    revenue_prediction = model.predict(input_data)[0]\n",
    "    \n",
    "    return {\"Predicted Revenue (USD)\": round(revenue_prediction, 2)}\n",
    "\n",
    "# Run the API\n",
    "if __name__ == \"__main__\":\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
